{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import csv\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from itertools import zip_longest\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from torch.optim import Adam, LBFGS\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Go up 3 levels: from jobs/ → spartan/ → simple-nn/\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "\n",
    "from model.model_data_class import Cus_Dataset, SimpleNN\n",
    "from model.train_test_loop import training_loop\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15ef6a890>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import .csv dataset \n",
    "file_path = \"../../data/heat_data_mushy.csv\"\n",
    "temp1 = pd.read_csv(file_path)\n",
    "\n",
    "temp2=temp1.copy()\n",
    "\n",
    "a = temp2.shape[0]\n",
    "\n",
    "pp1 = np.random.uniform(low=2,high=10,size=a)\n",
    "\n",
    "temp2['pp1']= pp1\n",
    "temp2['modtemp'] = temp2['temp']* temp2['pp1']\n",
    "\n",
    "\n",
    "temp3 = temp2.copy()\n",
    "cols = ['x', 't', 'pp1','modtemp']\n",
    "scalers = {}\n",
    "for col in cols:\n",
    "    scaler = MinMaxScaler()\n",
    "    temp3[col] = scaler.fit_transform(temp3[[col]])\n",
    "    scalers[col] = scaler\n",
    "\n",
    "# Save the scalers to a file\n",
    "scaler_file = '../tr-models/scalers.pkl'\n",
    "with open(scaler_file, 'wb') as f:\n",
    "    pickle.dump(scalers, f)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "feature_columns = ['x','t','pp1']\n",
    "target_column = 'modtemp'\n",
    "\n",
    "train_dataset = Cus_Dataset(temp3,feature_columns,target_column,train_ratio=0.8,\\\n",
    "                                   test_ratio=0.1, val_ratio=0.1,split='train')\n",
    "\n",
    "val_dataset = Cus_Dataset(temp3,feature_columns,target_column,train_ratio=0.8,\\\n",
    "                                   test_ratio=0.1, val_ratio=0.1,split='val')\n",
    "\n",
    "test_dataset = Cus_Dataset(temp3,feature_columns,target_column,train_ratio=0.8,\\\n",
    "                                   test_ratio=0.1, val_ratio=0.1,split='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5102, 0.8988, 0.4947]), tensor(0.4299))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 2662\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=512,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=512,shuffle=True)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# check for gpu\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available\")\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print('Using device:', device)\n",
    "\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3\n",
    "hidden_size = 20\n",
    "output_size = 1\n",
    "\n",
    "learning_rate = 0.005\n",
    "hidden_layers = 5\n",
    "\n",
    "epochs= 1\n",
    "\n",
    "model = SimpleNN(input_size,hidden_size,output_size,hidden_layers)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch 1,            | Training-Loss 3.0774e-04,| Test-Loss 1.1364e-04   |\n",
      "----------------------------------------------------------------------------------------------------\n",
      " \n",
      " \n",
      "----------------------------------------------------------------------------------------------------\n",
      "| Epoch 1,            | Training-Loss 3.0774e-04,| Test-Loss 1.1364e-04   |\n",
      "----------------------------------------------------------------------------------------------------\n",
      " \n"
     ]
    }
   ],
   "source": [
    "loss_train,loss_test,best_model = training_loop(epochs,model,optimizer,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../tr-models/best_model.pth\n",
      "Loss values saved to ../tr-models/loss_values.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "\n",
    "model_path = '../tr-models/best_model.pth'\n",
    "torch.save(best_model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "#save the loss values\n",
    "loss_path = '../tr-models/loss_values.pkl'\n",
    "with open(loss_path, 'wb') as f:\n",
    "    pickle.dump((loss_train, loss_test), f)\n",
    "print(f\"Loss values saved to {loss_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model on the test set\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
